name: 'CI: Lighthouse Performance Audit'

on:
  pull_request:
    branches:
      - master
    types:
      - opened
      - synchronize
      - reopened
  push:
    branches:
      - master

permissions:
  contents: read

# Cancel in-progress runs for the same PR
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  ci-lighthouse:
    name: 'CI: Lighthouse Performance Audit'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      statuses: write
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Calculate version (dry-run for PR)
        id: version
        run: |
          # Get short commit hash (7 chars)
          SHORT_HASH=$(git rev-parse --short=7 HEAD)
          # Use PR number instead of run number for PR builds
          PR_NUMBER="${{ github.event.pull_request.number }}"
          # Numeric version for npm (semver compliant): 0.0.PR-{pr_number}
          NUMERIC_VERSION="0.0.0-PR-${PR_NUMBER}"
          # Full version with commit hash for tag: 0.0.PR-{pr_number}.{hash}
          FULL_VERSION="0.0.PR-${PR_NUMBER}.${SHORT_HASH}"
          echo "numeric_version=$NUMERIC_VERSION" >> $GITHUB_OUTPUT
          echo "full_version=$FULL_VERSION" >> $GITHUB_OUTPUT
          echo "commit_hash=$SHORT_HASH" >> $GITHUB_OUTPUT
          echo "ðŸ“¦ Calculated PR version: $FULL_VERSION (npm: $NUMERIC_VERSION)"

      - name: Setup Node.js
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Update package.json version for build
        run: |
          npm version ${{ steps.version.outputs.numeric_version }} --no-git-tag-version --allow-same-version

      - name: Build standalone HTML
        run: npm run build:standalone
        env:
          BUILD_COMMIT: ${{ steps.version.outputs.commit_hash }}
          BUILD_COMMIT_URL: ${{ github.server_url }}/${{ github.repository }}/commit/${{ steps.version.outputs.commit_hash }}
          BUILD_WORKFLOW_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          RELEASE_URL: 'https://github.com/${{ github.repository }}/pull/${{ github.event.pull_request.number }}'

      - name: Run Lighthouse CI on standalone build
        id: lighthouse
        env:
          LHCI_GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Use separate commands instead of autorun to preserve .lighthouseci/ for artifacts
          # Collect performance data
          npx @lhci/cli@0.14.0 collect --config=config/lighthouserc.cjs

          # Run assertions
          npx @lhci/cli@0.14.0 assert --config=config/lighthouserc.cjs

          # Copy .lighthouseci/ before upload (upload command deletes files after uploading to GCS)
          cp -r .lighthouseci .lighthouseci-backup

          # Upload and capture the report URL
          UPLOAD_OUTPUT=$(npx @lhci/cli@0.14.0 upload --config=config/lighthouserc.cjs 2>&1)
          echo "$UPLOAD_OUTPUT"

          # Extract both viewer URL (with comparison) and direct storage URL
          VIEWER_URL=$(echo "$UPLOAD_OUTPUT" | grep -oE 'https://googlechrome\.github\.io/lighthouse-ci/viewer/\?[^[:space:]]+' | head -n 1)

          # Extract the direct storage URL (current report) from either:
          # 1. compareReport parameter in viewer URL (when comparison exists)
          # 2. baseReport parameter in viewer URL (when only one report)
          # 3. Direct storage URL in output (fallback)
          if [ -n "$VIEWER_URL" ]; then
            DIRECT_URL=$(echo "$VIEWER_URL" | grep -oE 'compareReport=https[^&]+' | sed 's/compareReport=//' | sed 's/%3A/:/g' | sed 's/%2F/\//g')
            if [ -z "$DIRECT_URL" ]; then
              DIRECT_URL=$(echo "$VIEWER_URL" | grep -oE 'baseReport=https[^&]+' | sed 's/baseReport=//' | sed 's/%3A/:/g' | sed 's/%2F/\//g')
            fi
          else
            DIRECT_URL=$(echo "$UPLOAD_OUTPUT" | grep -oE 'https://storage\.googleapis\.com/[^[:space:]]+\.html' | head -n 1)
          fi

          # Output both URLs
          echo "report_url=$VIEWER_URL" >> $GITHUB_OUTPUT
          echo "direct_report_url=$DIRECT_URL" >> $GITHUB_OUTPUT

          if [ -n "$VIEWER_URL" ]; then
            echo "ðŸ“Š Lighthouse Comparison View: $VIEWER_URL"
          fi
          if [ -n "$DIRECT_URL" ]; then
            echo "ðŸ“„ Direct Report: $DIRECT_URL"
          fi
          if [ -z "$VIEWER_URL" ] && [ -z "$DIRECT_URL" ]; then
            echo "âš ï¸  No report URLs found in upload output"
          fi

          # Restore the directory for artifact upload
          rm -rf .lighthouseci
          mv .lighthouseci-backup .lighthouseci
      - name: Generate job summary
        if: always()
        env:
          VIEWER_URL: ${{ steps.lighthouse.outputs.report_url }}
          DIRECT_URL: ${{ steps.lighthouse.outputs.direct_report_url }}
        run: |
          python3 -c '
          import json
          import os
          import glob

          print("## Lighthouse CI Results")

          # Add report URLs if available
          viewer_url = os.environ.get("VIEWER_URL", "")
          direct_url = os.environ.get("DIRECT_URL", "")

          if direct_url:
              print(f"\nðŸ“„ **[View Report]({direct_url})**")

          if viewer_url and viewer_url != direct_url:
              print(f"ðŸ“Š **[View Comparison]({viewer_url})**")

          if direct_url or viewer_url:
              print("")  # Add spacing

          files = glob.glob(".lighthouseci/lhr-*.json")
          if not files:
              print("\nNo Lighthouse reports found.")
          else:
              # Separate mobile and desktop scores
              mobile_scores = {"performance": [], "accessibility": [], "best-practices": [], "seo": []}
              desktop_scores = {"performance": [], "accessibility": [], "best-practices": [], "seo": []}
              
              for f in files:
                  try:
                      with open(f, "r") as json_file:
                          data = json.load(json_file)
                          form_factor = data.get("configSettings", {}).get("formFactor", "unknown")
                          categories = data.get("categories", {})
                          
                          target = mobile_scores if form_factor == "mobile" else desktop_scores
                          
                          for key in target.keys():
                              if key in categories:
                                  target[key].append(categories[key].get("score", 0))
                  except Exception as e:
                      pass
              
              # Print mobile results
              if mobile_scores["performance"]:
                  print("\n### ðŸ“± Mobile")
                  print("| Category | Score |")
                  print("| --- | --- |")
                  for key, scores in mobile_scores.items():
                      if scores:
                          avg_score = (sum(scores) / len(scores)) * 100
                          emoji = "ðŸŸ¢" if avg_score >= 90 else "ðŸŸ " if avg_score >= 50 else "ðŸ”´"
                          print(f"| {key.replace(\"-\", \" \").title()} | {emoji} {avg_score:.0f} |")
              
              # Print desktop results
              if desktop_scores["performance"]:
                  print("\n### ðŸ–¥ï¸ Desktop")
                  print("| Category | Score |")
                  print("| --- | --- |")
                  for key, scores in desktop_scores.items():
                      if scores:
                          avg_score = (sum(scores) / len(scores)) * 100
                          emoji = "ðŸŸ¢" if avg_score >= 90 else "ðŸŸ " if avg_score >= 50 else "ðŸ”´"
                          print(f"| {key.replace(\"-\", \" \").title()} | {emoji} {avg_score:.0f} |")
              
              if not mobile_scores["performance"] and not desktop_scores["performance"]:
                  print("\nNo valid data found in reports.")

          print("\n_See artifacts for detailed reports._")
          ' > lighthouse_summary.md
          cat lighthouse_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Update PR Comment
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            const updateComment = require('./.github/scripts/update-pr-comment.cjs');

            let body = 'Lighthouse CI failed or did not run correctly.';
            if (fs.existsSync('lighthouse_summary.md')) {
              body = fs.readFileSync('lighthouse_summary.md', 'utf8');
              // Remove the header from the body since updateComment adds it
              body = body.replace(/^## .*?\n/, '');
            }

            await updateComment({
              github,
              context,
              header: 'Lighthouse CI Results',
              body,
              workflowYaml: 'ci-lighthouse.yml'
            });
